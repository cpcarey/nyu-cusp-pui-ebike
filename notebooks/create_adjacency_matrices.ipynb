{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "stable-atlantic",
   "metadata": {},
   "source": [
    "This notebook generates an adjacency matrix for stations or clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "spiritual-dragon",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from functools import reduce\n",
    "from geopy import Point\n",
    "from geopy import distance\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "curious-confirmation",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPORT_DIR = '../data/exports/adjacency_matrix'\n",
    "CENTROIDS_DIR = '../data/exports'\n",
    "LABELS_DIR = '../data/exports'\n",
    "SHAPEFILE_DIR = '../data/shapefiles/zipcodes'\n",
    "STATIONS_DIR = '../data/exports'\n",
    "TRIPS_DIR = '../data/raw'\n",
    "\n",
    "# TODO(cpcarey): Convert to enum.\n",
    "# Options include: 'displacement', 'elevation', 'trip_count',\n",
    "# 'trip_count_classic', 'trip_count_electric'\n",
    "VARIABLE = 'trip_count_electric'\n",
    "\n",
    "TRIP_DATES = [\n",
    "    '202007',\n",
    "    '202008',\n",
    "    '202009',\n",
    "    '202010',\n",
    "    '202011',\n",
    "    '202012',\n",
    "    '202101',\n",
    "    '202102',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auburn-columbia",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLUSTER = True\n",
    "K = 25\n",
    "NODE_TYPE = 'label' if CLUSTER else 'station_id'\n",
    "ID1 = f'start_{NODE_TYPE}'\n",
    "ID2 = f'end_{NODE_TYPE}'\n",
    "\n",
    "if CLUSTER:\n",
    "    EXPORT_DIR = f'{EXPORT_DIR}/k{K}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriented-pasta",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnalysisConfig:\n",
    "\n",
    "    def __init__(self,\n",
    "                 centroids_path='',\n",
    "                 export_path='',\n",
    "                 labels_path='',\n",
    "                 stations_path='',\n",
    "                 trips_path_suffix=''):\n",
    "        self.centroids_path = centroids_path\n",
    "        self.export_path = export_path\n",
    "        self.labels_path = labels_path\n",
    "        self.stations_path = stations_path\n",
    "        self.trips_path_suffix = trips_path_suffix\n",
    "        self.station_ids = None\n",
    "\n",
    "    def get_station_ids(self):\n",
    "        # Cache value after calculation.\n",
    "        if self.station_ids == None:\n",
    "            self.station_ids = set(\n",
    "                pd.read_csv(self.stations_path)['station_id'].astype(str))\n",
    "        return self.station_ids\n",
    "\n",
    "    def get_trips_dfs(self):\n",
    "        trips_paths = [\n",
    "            '{}/{}{}'.format(TRIPS_DIR, date, self.trips_path_suffix)\n",
    "            for date in TRIP_DATES\n",
    "        ]\n",
    "        dfs = [pd.read_csv(path) for path in trips_paths]\n",
    "        for df in dfs:\n",
    "            df['start_station_id'] = df['start_station_id'].astype(str)\n",
    "            df['end_station_id'] = df['end_station_id'].astype(str)\n",
    "        return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vertical-humidity",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_sf = AnalysisConfig(\n",
    "    centroids_path=f'{CENTROIDS_DIR}/centroids_k{K}_sf.csv',\n",
    "    export_path=f'{EXPORT_DIR}/{VARIABLE}_sf.csv',\n",
    "    labels_path=f'{LABELS_DIR}/cluster_labels_k{K}_sf.csv',\n",
    "    stations_path=f'{STATIONS_DIR}/SF_ele_single station.csv',\n",
    "    trips_path_suffix='-baywheels-tripdata.csv',\n",
    ")\n",
    "\n",
    "config_dc = AnalysisConfig(\n",
    "    centroids_path=f'{CENTROIDS_DIR}/centroids_k{K}_dc.csv',\n",
    "    export_path=f'{EXPORT_DIR}/{VARIABLE}_dc.csv',\n",
    "    labels_path=f'{LABELS_DIR}/cluster_labels_k{K}_dc.csv',\n",
    "    stations_path=f'{STATIONS_DIR}/DC_ele_single station.csv',\n",
    "    trips_path_suffix='-capitalbikeshare-tripdata.csv',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subtle-button",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = config_dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innovative-punch",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_trips(df, config):\n",
    "    \"\"\"Drops missing and non-matching station IDs.\"\"\"\n",
    "    REQUIRED_COLUMNS = ['start_station_id', 'end_station_id']\n",
    "    \n",
    "    # Drop missing station IDs.\n",
    "    new_df = df.dropna(subset=REQUIRED_COLUMNS)\n",
    "    \n",
    "    # Drop non-matching station IDs.\n",
    "    for column in REQUIRED_COLUMNS:\n",
    "        new_df = new_df[new_df[column].isin(config.get_station_ids())]\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sought-applicant",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'trip_count' in VARIABLE:\n",
    "    trips_dfs = [clean_trips(df, config) for df in config.get_trips_dfs()]\n",
    "    all_trips_df = pd.concat(trips_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structured-battle",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'trip_count' in VARIABLE:\n",
    "    grouping_df = all_trips_df\n",
    "    if 'classic' in VARIABLE:\n",
    "        # WARNING: SF changes 'docked_bike' to 'classic_bike' over time period.\n",
    "        grouping_df = grouping_df[grouping_df['rideable_type'].isin(['classic_bike', 'docked_bike'])]\n",
    "    if 'electric' in VARIABLE:\n",
    "        grouping_df = grouping_df[grouping_df['rideable_type'] == 'electric_bike']\n",
    "    \n",
    "    all_trips_counts = grouping_df.groupby(['start_station_id',\n",
    "                                             'end_station_id']).agg({\n",
    "                                                 'ride_id': 'count'\n",
    "                                             }).rename(columns={\n",
    "                                                 'ride_id': 'trip_count',\n",
    "                                             }).reset_index()\n",
    "        \n",
    "if 'trip_count' in VARIABLE:\n",
    "    display(all_trips_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mechanical-funeral",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'trip_count' in VARIABLE:\n",
    "    if CLUSTER:\n",
    "        start_df = pd.read_csv(config.labels_path).rename(columns={\n",
    "            'station_id': 'start_station_id',\n",
    "            'label': 'start_label',\n",
    "        })\n",
    "        start_df['start_station_id'] = start_df['start_station_id'].astype(str)\n",
    "        end_df = pd.read_csv(config.labels_path).rename(columns={\n",
    "            'station_id': 'end_station_id',\n",
    "            'label': 'end_label',\n",
    "        })\n",
    "        end_df['end_station_id'] = end_df['end_station_id'].astype(str)\n",
    "        cluster_counts_df = pd.merge(all_trips_counts,\n",
    "                                     start_df,\n",
    "                                     on='start_station_id',\n",
    "                                     how='left')\n",
    "        cluster_counts_df = pd.merge(cluster_counts_df,\n",
    "                                     end_df,\n",
    "                                     on='end_station_id',\n",
    "                                     how='left')\n",
    "        cluster_counts_df = cluster_counts_df.drop(\n",
    "            columns=['start_station_id', 'end_station_id'])\n",
    "        cluster_counts_df = cluster_counts_df.groupby(['start_label',\n",
    "                                                       'end_label']).agg({\n",
    "                                                           'trip_count': 'sum'\n",
    "                                                       }).reset_index()\n",
    "        display(cluster_counts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "democratic-treasure",
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids_df = None\n",
    "if CLUSTER:\n",
    "    centroids_df = pd.read_csv(config.centroids_path)\n",
    "    display(centroids_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collective-progress",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_df = centroids_df if CLUSTER else stations_df\n",
    "\n",
    "def get_distance(point1, point2):\n",
    "    return distance.geodesic(point1, point2).m\n",
    "\n",
    "def get_point(node_id):\n",
    "    return Point(nodes_df.loc[node_id]['lat'], nodes_df.loc[node_id]['lng'])\n",
    "\n",
    "def get_displacement(node_id1, node_id2):\n",
    "    return get_distance(get_point(node_id1), get_point(node_id2))\n",
    "\n",
    "def get_elevation_change(node_id1, node_id2):\n",
    "    return (nodes_df.loc[node_id2]['elevation'] - \n",
    "            nodes_df.loc[node_id1]['elevation'])\n",
    "\n",
    "def get_gradient(node_id1, node_id2):\n",
    "    return get_elevation_change(node_id1, node_id2) / get_displacement(node_id1, node_id2)\n",
    "\n",
    "def get_trip_count(node_id1, node_id2):\n",
    "    df = cluster_counts_df if CLUSTER else all_trips_counts\n",
    "    NODE_ID = 'label' if CLUSTER else 'station_id'\n",
    "    \n",
    "    row = df[(df[f'start_{NODE_ID}'] == node_id1) &\n",
    "             (df[f'end_{NODE_ID}'] == node_id2)]\n",
    "    if len(row) == 0:\n",
    "        return 0\n",
    "    return row.iloc[:, -1:].values[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optical-fluid",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threatened-canadian",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_matrix = pd.DataFrame(index=nodes_df.index, columns=nodes_df.index)\n",
    "\n",
    "if VARIABLE == 'displacement':\n",
    "    adj_matrix = adj_matrix.apply(lambda row: row.index.to_series().apply(\n",
    "        lambda col_name: get_displacement(row.name, col_name)),\n",
    "                                  axis=1)\n",
    "elif VARIABLE == 'elevation':\n",
    "    adj_matrix = adj_matrix.apply(lambda row: row.index.to_series().apply(\n",
    "        lambda col_name: get_elevation_change(row.name, col_name)),\n",
    "                                  axis=1)\n",
    "elif 'trip_count' in VARIABLE:\n",
    "    adj_matrix = adj_matrix.apply(lambda row: row.index.to_series().apply(\n",
    "        lambda col_name: get_trip_count(row.name, col_name)), axis=1)\n",
    "    \n",
    "adj_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "israeli-comedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_matrix.index = adj_matrix.index.rename(NODE_TYPE)\n",
    "adj_matrix.to_csv(config.export_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emerging-envelope",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_adj_matrix = pd.read_csv(config.export_path, index_col=1)\n",
    "display(csv_adj_matrix.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outdoor-slovenia",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
